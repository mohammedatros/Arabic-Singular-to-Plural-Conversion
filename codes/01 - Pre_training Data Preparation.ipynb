{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf_dUQL_lcOz"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tytDsTGlCs2q",
    "outputId": "449655c7-edd3-45e7-a1f5-1e35680d57a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyArabic in /usr/local/lib/python3.7/dist-packages (0.6.14)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from PyArabic) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# install PyArabic library for Arabic preprocessing\n",
    "!pip install PyArabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tB3hTHNrc_vN",
    "outputId": "cafcdb3b-33de-449c-c344-cbe5b5f2245d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.16.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
     ]
    }
   ],
   "source": [
    "# install tensorflow_addons for AdamW optimizer\n",
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6nYX2Lsfeki"
   },
   "outputs": [],
   "source": [
    "# Standard libraries imports\n",
    "import io\n",
    "import re\n",
    "import ast\n",
    "import math\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "import pyarabic.araby as araby\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NOvELLKlinQ"
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NY2Le0HZf2w4"
   },
   "outputs": [],
   "source": [
    "# configurations class\n",
    "class config:\n",
    "\n",
    "  MAXLEN = 17 # maximum length of sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzdOcFqOMUf5"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEb7_GE9V0f5",
    "outputId": "6d087692-fde2-4334-8a6e-79aa4aacd0fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Arabic Characters: 38\n"
     ]
    }
   ],
   "source": [
    "# list of all Arabic characters\n",
    "chars = list('اٱبتةثجحخدذرزسشصضطظعغفقكلمنهويءآأؤإئىی')\n",
    "print('Number of Arabic Characters:', len(chars))\n",
    "\n",
    "# character to index dictionary\n",
    "char_to_index = dict((char, index+3) for (index, char) in enumerate(chars))\n",
    "# index to character dictionary\n",
    "index_to_char=  dict((index+3, char) for (index, char) in enumerate(chars))\n",
    "\n",
    "char_to_index['p'] = 0 # pad\n",
    "char_to_index['s'] = 1 # separator\n",
    "char_to_index['_'] = 2 # mask\n",
    "\n",
    "\n",
    "index_to_char[0] = 'p' # pad\n",
    "index_to_char[1] = 's' # separator\n",
    "index_to_char[2] = '_' # mask\n",
    "\n",
    "# additional char_to_index and index_to_char extracted manually as shown in next \n",
    "# cells. They were extracted and then saved into a CSV file\n",
    "df = pd.read_csv('https://drive.google.com/uc?export=download&id=1lQFU7XFy82-1dE5kPK7yDLpJ6tleycCC')\n",
    "chars_2 = df['char'].values.tolist()\n",
    "indexes_2 = df['value'].values.tolist()\n",
    "del df\n",
    "\n",
    "# additional character to index dictionary\n",
    "char_to_index_2 = dict(zip(chars_2, indexes_2))\n",
    "# additional index to character dictionary\n",
    "index_to_char_2 = dict(zip(indexes_2, chars_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XiGxDZY40x0r",
    "outputId": "fc800e14-1503-45ba-ec87-187cb903d15f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download text_1 to be used for pretraining\n",
    "url = 'https://drive.google.com/uc?export=download&id=1-A7OVKYutL6ZIUfy_yewUN68jK0VmhHd'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('Quran_listf.txt', 'wb').write(r.content)\n",
    "\n",
    "# download text_2 to be used for pretraining\n",
    "url = 'https://drive.google.com/uc?export=download&id=1-1IEr0bMwyAZHOKGpjsbMM6ttjnwQmDZ'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('corpus_filtred.txt', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0ZOWsACHmBq",
    "outputId": "0d80ff5d-a776-4cc3-fa42-51b0579d999c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 2910526\n"
     ]
    }
   ],
   "source": [
    "# read the text files\n",
    "with open('/content/Quran_listf.txt') as f:\n",
    "  text_1 = f.read()\n",
    "\n",
    "# read the text files\n",
    "with open('/content/corpus_filtred.txt') as f:\n",
    "  text_2 = f.read()\n",
    "\n",
    "# concatenate text files\n",
    "text = text_1 + ' ' + text_2\n",
    "# remove teh new line token\n",
    "text = text.replace('\\n', ' ')\n",
    "# convert text to a list of words\n",
    "text_as_list = text.split()\n",
    "print('Number of tokens:', len(text_as_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1V_GnRAfJDPd",
    "outputId": "12f62039-059a-4479-e799-ebb97c7525e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2910526/2910526 [00:28<00:00, 101072.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# limit the maximum length of a token in the dataset to 15\n",
    "# remove all outliers that lie beyond this region\n",
    "# figure out the maximum and minimum length in the dataset after outlier removal\n",
    "max_len = 0 # instantiate max length\n",
    "min_len = 100 # instantiate min length\n",
    "clean_text_list = [] # instantiate a list to collect cleaned text \n",
    "\n",
    "# iterate over each token in the dataset\n",
    "for i, token in tqdm(enumerate(text_as_list), total=len(text_as_list)):\n",
    "  if len(token) <= 15:\n",
    "    clean_text_list.append(re.sub('\\W+',' ', araby.strip_diacritics(token)).replace('ـ', 's').replace(' ', 's'))\n",
    "\n",
    "    if len(token) > max_len:\n",
    "      max_len = len(token)\n",
    "\n",
    "    if len(token) < min_len:\n",
    "      min_len = len(token)\n",
    "\n",
    "# print max and min lengths\n",
    "max_len, min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6RsBz8q1Cxb",
    "outputId": "b4f38131-19b4-4091-c941-42429e338cb3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2899236/2899236 [00:01<00:00, 1627766.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# construct a pure text from the clean list of tokens\n",
    "pure_text = ''\n",
    "for token in tqdm(clean_text_list):\n",
    "  pure_text += token + 's'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upZLjYCcAmBy"
   },
   "source": [
    "### Additional characters (manual entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-gtgLhNrViK",
    "outputId": "bcc4fd61-677b-4eee-9da4-cec8bbf80831"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2899422/2899422 [00:02<00:00, 1018281.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# pure_text_as_list = pure_text.split('s')\n",
    "# all_chars = []\n",
    "# for text in tqdm(pure_text_as_list):\n",
    "#   temp_list = list(text)\n",
    "#   all_chars.extend(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhvALUMorVnP",
    "outputId": "a7df54c0-32a4-4c08-d2a5-3d1290c8c188"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique_chars = list(set(all_chars))\n",
    "# len(unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seRiVUx_tveo",
    "outputId": "4c42dee0-72b6-4c47-9f49-594dd75c1fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0 or 10\n",
      "l\n",
      "0 or 10\n",
      "ﳑ\n",
      "0 or 10\n",
      "ﺌ\n",
      "0 or 1ئ\n",
      "similar charئ\n",
      "**************************************************\n",
      "ﺰ\n",
      "0 or 11\n",
      "similar charز\n",
      "**************************************************\n",
      "ﹰ\n",
      "0 or 10\n",
      "ﻆ\n",
      "0 or 11\n",
      "similar charظ\n",
      "**************************************************\n",
      "ﱘ\n",
      "0 or 10\n",
      "ﺔ\n",
      "0 or 11\n",
      "similar charة\n",
      "**************************************************\n",
      "ﻔ\n",
      "0 or 11\n",
      "similar charف\n",
      "**************************************************\n",
      "ب\n",
      "0 or 11\n",
      "similar charب\n",
      "**************************************************\n",
      "ف\n",
      "0 or 11\n",
      "similar charف\n",
      "**************************************************\n",
      "٤\n",
      "0 or 10\n",
      "ت\n",
      "0 or 11\n",
      "similar charت\n",
      "**************************************************\n",
      "ق\n",
      "0 or 11\n",
      "similar charق\n",
      "**************************************************\n",
      "6\n",
      "0 or 10\n",
      "ﺭ\n",
      "0 or 11\n",
      "similar charر\n",
      "**************************************************\n",
      "ﺦ\n",
      "0 or 11\n",
      "similar charخ\n",
      "**************************************************\n",
      "ﻚ\n",
      "0 or 11\n",
      "similar charك\n",
      "**************************************************\n",
      "ﺼ\n",
      "0 or 11\n",
      "similar charص\n",
      "**************************************************\n",
      "٧\n",
      "0 or 10\n",
      "ﺄ\n",
      "0 or 11\n",
      "similar charأ\n",
      "**************************************************\n",
      "ﺊ\n",
      "0 or 11\n",
      "similar charئ\n",
      "**************************************************\n",
      "د\n",
      "0 or 11\n",
      "similar charد\n",
      "**************************************************\n",
      "ﺙ\n",
      "0 or 11\n",
      "similar charث\n",
      "**************************************************\n",
      "ﺇ\n",
      "0 or 11\n",
      "similar charإ\n",
      "**************************************************\n",
      "ﺲ\n",
      "0 or 11\n",
      "similar charس\n",
      "**************************************************\n",
      "ﻧ\n",
      "0 or 11\n",
      "similar charذ\n",
      "**************************************************\n",
      "7\n",
      "0 or 10\n",
      "ﻟ\n",
      "0 or 11\n",
      "similar charل\n",
      "**************************************************\n",
      "ﺺ\n",
      "0 or 11\n",
      "similar charص\n",
      "**************************************************\n",
      "ﻺ\n",
      "0 or 10\n",
      "ﺻ\n",
      "0 or 11\n",
      "similar charص\n",
      "**************************************************\n",
      "ﺠ\n",
      "0 or 11\n",
      "similar charج\n",
      "**************************************************\n",
      "ز\n",
      "0 or 11\n",
      "similar charز\n",
      "**************************************************\n",
      "ﳛ\n",
      "0 or 10\n",
      "ﱡ\n",
      "0 or 10\n",
      "ﻸ\n",
      "0 or 10\n",
      "ﺝ\n",
      "0 or 11\n",
      "similar charج\n",
      "**************************************************\n",
      "ﰲ\n",
      "0 or 10\n",
      "ﻄ\n",
      "0 or 11\n",
      "similar charط\n",
      "**************************************************\n",
      "ﺮ\n",
      "0 or 11\n",
      "similar charر\n",
      "**************************************************\n",
      "س\n",
      "0 or 11\n",
      "similar charس\n",
      "**************************************************\n",
      "ﱴ\n",
      "0 or 10\n",
      "ﹲ\n",
      "0 or 10\n",
      "ﺹ\n",
      "0 or 11\n",
      "similar charص\n",
      "**************************************************\n",
      "ﻑ\n",
      "0 or 11\n",
      "similar charف\n",
      "**************************************************\n",
      "ﺷ\n",
      "0 or 11\n",
      "similar charش\n",
      "**************************************************\n",
      "ﻓ\n",
      "0 or 11\n",
      "similar charف\n",
      "**************************************************\n",
      "ﺒ\n",
      "0 or 11\n",
      "similar charب\n",
      "**************************************************\n",
      "ﺛ\n",
      "0 or 11\n",
      "similar charث\n",
      "**************************************************\n",
      "ﻊ\n",
      "0 or 11\n",
      "similar charع\n",
      "**************************************************\n",
      "ﻞ\n",
      "0 or 11\n",
      "similar charل\n",
      "**************************************************\n",
      "ﻵ\n",
      "0 or 10\n",
      "ﺉ\n",
      "0 or 11\n",
      "similar charئ\n",
      "**************************************************\n",
      "ﲡ\n",
      "0 or 10\n",
      "9\n",
      "0 or 10\n",
      "٩\n",
      "0 or 10\n",
      "ﱟ\n",
      "0 or 10\n",
      "ض\n",
      "0 or 11\n",
      "similar charض\n",
      "**************************************************\n",
      "ﻃ\n",
      "0 or 11\n",
      "similar charط\n",
      "**************************************************\n",
      "ﻨ\n",
      "0 or 11\n",
      "similar charن\n",
      "**************************************************\n",
      "ﺈ\n",
      "0 or 11\n",
      "similar charإ\n",
      "**************************************************\n",
      "ﻩ\n",
      "0 or 11\n",
      "similar charه\n",
      "**************************************************\n",
      "ﷲ\n",
      "0 or 10\n",
      "e\n",
      "0 or 10\n",
      "ﻼ\n",
      "0 or 10\n",
      "ﻲ\n",
      "0 or 11\n",
      "similar charي\n",
      "**************************************************\n",
      "ى\n",
      "0 or 11\n",
      "similar charى\n",
      "**************************************************\n",
      "ﻻ\n",
      "0 or 10\n",
      "m\n",
      "0 or 10\n",
      "م\n",
      "0 or 11\n",
      "similar charم\n",
      "**************************************************\n",
      "ع\n",
      "0 or 11\n",
      "similar charع\n",
      "**************************************************\n",
      "ﺢ\n",
      "0 or 11\n",
      "similar charح\n",
      "**************************************************\n",
      "ش\n",
      "0 or 11\n",
      "similar charش\n",
      "**************************************************\n",
      "ﺞ\n",
      "0 or 11\n",
      "similar charج\n",
      "**************************************************\n",
      "ﱂ\n",
      "0 or 10\n",
      "ك\n",
      "0 or 11\n",
      "similar charك\n",
      "**************************************************\n",
      "ﻰ\n",
      "0 or 11\n",
      "similar charى\n",
      "**************************************************\n",
      "٠\n",
      "0 or 10\n",
      "ئ\n",
      "0 or 11\n",
      "similar charئ\n",
      "**************************************************\n",
      "ﺀ\n",
      "0 or 11\n",
      "similar charء\n",
      "**************************************************\n",
      "ﻇ\n",
      "0 or 11\n",
      "similar charظ\n",
      "**************************************************\n",
      "ﻤ\n",
      "0 or 11\n",
      "similar charم\n",
      "**************************************************\n",
      "ﺩ\n",
      "0 or 11\n",
      "similar charد\n",
      "**************************************************\n",
      "إ\n",
      "0 or 11\n",
      "similar charإ\n",
      "**************************************************\n",
      "ﺯ\n",
      "0 or 11\n",
      "similar charز\n",
      "**************************************************\n",
      "ﺘ\n",
      "0 or 11\n",
      "similar charت\n",
      "**************************************************\n",
      "ﺱ\n",
      "0 or 11\n",
      "similar charس\n",
      "**************************************************\n",
      "ﲔ\n",
      "0 or 10\n",
      "٦\n",
      "0 or 10\n",
      "ﻕ\n",
      "0 or 11\n",
      "similar charق\n",
      "**************************************************\n",
      "ﺆ\n",
      "0 or 11\n",
      "similar charؤ\n",
      "**************************************************\n",
      "ﲑ\n",
      "0 or 10\n",
      "ﳚ\n",
      "0 or 10\n",
      "f\n",
      "0 or 10\n",
      "ﻢ\n",
      "0 or 11\n",
      "similar charم\n",
      "**************************************************\n",
      "٣\n",
      "0 or 10\n",
      "ﻂ\n",
      "0 or 11\n",
      "similar charط\n",
      "**************************************************\n",
      "ﻴ\n",
      "0 or 11\n",
      "similar charي\n",
      "**************************************************\n",
      "ﺜ\n",
      "0 or 11\n",
      "similar charث\n",
      "**************************************************\n",
      "ﺿ\n",
      "0 or 11\n",
      "similar charض\n",
      "**************************************************\n",
      "ﱐ\n",
      "0 or 10\n",
      "ر\n",
      "0 or 11\n",
      "similar charر\n",
      "**************************************************\n",
      "ﲰ\n",
      "0 or 10\n",
      "٥\n",
      "0 or 10\n",
      "ﻉ\n",
      "0 or 11\n",
      "similar charع\n",
      "**************************************************\n",
      "ﺡ\n",
      "0 or 11\n",
      "similar charح\n",
      "**************************************************\n",
      "ﻬ\n",
      "0 or 11\n",
      "similar charه\n",
      "**************************************************\n",
      "ح\n",
      "0 or 11\n",
      "similar charح\n",
      "**************************************************\n",
      "ظ\n",
      "0 or 11\n",
      "similar charظ\n",
      "**************************************************\n",
      "ن\n",
      "0 or 11\n",
      "similar charن\n",
      "**************************************************\n",
      "ﻖ\n",
      "0 or 11\n",
      "similar charق\n",
      "**************************************************\n",
      "ة\n",
      "0 or 11\n",
      "similar charة\n",
      "**************************************************\n",
      "ﺸ\n",
      "0 or 11\n",
      "similar charش\n",
      "**************************************************\n",
      "ﻣ\n",
      "0 or 11\n",
      "similar charم\n",
      "**************************************************\n",
      "ﻛ\n",
      "0 or 11\n",
      "similar charك\n",
      "**************************************************\n",
      "ذ\n",
      "0 or 11\n",
      "similar charذ\n",
      "**************************************************\n",
      "ﳌ\n",
      "0 or 10\n",
      "i\n",
      "0 or 10\n",
      "ﹶ\n",
      "0 or 10\n",
      "ﺫ\n",
      "0 or 11\n",
      "similar charذ\n",
      "**************************************************\n",
      "ﻐ\n",
      "0 or 11\n",
      "similar charغ\n",
      "**************************************************\n",
      "ﻯ\n",
      "0 or 11\n",
      "similar charى\n",
      "**************************************************\n",
      "ص\n",
      "0 or 11\n",
      "similar charص\n",
      "**************************************************\n",
      "ﺖ\n",
      "0 or 11\n",
      "similar charت\n",
      "**************************************************\n",
      "أ\n",
      "0 or 11\n",
      "similar charأ\n",
      "**************************************************\n",
      "ه\n",
      "0 or 11\n",
      "similar charه\n",
      "**************************************************\n",
      "ﺑ\n",
      "0 or 11\n",
      "similar charب\n",
      "**************************************************\n",
      "5\n",
      "0 or 10\n",
      "ﺣ\n",
      "0 or 11\n",
      "similar charح\n",
      "**************************************************\n",
      "ﺗ\n",
      "0 or 11\n",
      "similar charت\n",
      "**************************************************\n",
      "ﱢ\n",
      "0 or 10\n",
      "ﻀ\n",
      "0 or 11\n",
      "similar charض\n",
      "**************************************************\n",
      "ﻱ\n",
      "0 or 11\n",
      "similar charي\n",
      "**************************************************\n",
      "ﹾ\n",
      "0 or 10\n",
      "ﺍ\n",
      "0 or 11\n",
      "similar charا\n",
      "**************************************************\n",
      "ﱃ\n",
      "0 or 10\n",
      "ﳏ\n",
      "0 or 10\n",
      "ﺳ\n",
      "0 or 11\n",
      "similar charس\n",
      "**************************************************\n",
      "ﺐ\n",
      "0 or 11\n",
      "similar charب\n",
      "**************************************************\n",
      "ﱪ\n",
      "0 or 10\n",
      "ﱞ\n",
      "0 or 10\n",
      "ﱵ\n",
      "0 or 10\n",
      "ﻫ\n",
      "0 or 11\n",
      "similar charه\n",
      "**************************************************\n",
      "ﻪ\n",
      "0 or 11\n",
      "similar charه\n",
      "**************************************************\n",
      "ﻎ\n",
      "0 or 11\n",
      "similar charغ\n",
      "**************************************************\n",
      "١\n",
      "0 or 10\n",
      "ء\n",
      "0 or 11\n",
      "similar charء\n",
      "**************************************************\n",
      "0\n",
      "0 or 10\n",
      "ﻮ\n",
      "0 or 11\n",
      "similar charو\n",
      "**************************************************\n",
      "ﻘ\n",
      "0 or 11\n",
      "similar charق\n",
      "**************************************************\n",
      "ﻥ\n",
      "0 or 11\n",
      "similar charن\n",
      "**************************************************\n",
      "ﻷ\n",
      "0 or 10\n",
      "ﺾ\n",
      "0 or 11\n",
      "similar charض\n",
      "**************************************************\n",
      "ﺎ\n",
      "0 or 10\n",
      "ﻳ\n",
      "0 or 11\n",
      "similar charي\n",
      "**************************************************\n",
      "ﻠ\n",
      "0 or 10\n",
      "ﺽ\n",
      "0 or 11\n",
      "similar charض\n",
      "**************************************************\n",
      "ﻈ\n",
      "0 or 11\n",
      "similar charظ\n",
      "**************************************************\n",
      "ﳊ\n",
      "0 or 10\n",
      "ا\n",
      "0 or 11\n",
      "similar charا\n",
      "**************************************************\n",
      "ﻋ\n",
      "0 or 11\n",
      "similar charع\n",
      "**************************************************\n",
      "ﻍ\n",
      "0 or 11\n",
      "similar charغ\n",
      "**************************************************\n",
      "ﳍ\n",
      "0 or 10\n",
      "ﱰ\n",
      "0 or 10\n",
      "ﻦ\n",
      "0 or 11\n",
      "similar charن\n",
      "**************************************************\n",
      "ﺤ\n",
      "0 or 11\n",
      "similar charح\n",
      "**************************************************\n",
      "ﺓ\n",
      "0 or 11\n",
      "similar charة\n",
      "**************************************************\n",
      "ﺏ\n",
      "0 or 11\n",
      "similar charب\n",
      "**************************************************\n",
      "ل\n",
      "0 or 11\n",
      "similar charل\n",
      "**************************************************\n",
      "ﻅ\n",
      "0 or 11\n",
      "similar charظ\n",
      "**************************************************\n",
      "3\n",
      "0 or 10\n",
      "ﺟ\n",
      "0 or 11\n",
      "similar charج\n",
      "**************************************************\n",
      "ﺵ\n",
      "0 or 11\n",
      "similar charش\n",
      "**************************************************\n",
      "ﺪ\n",
      "0 or 11\n",
      "similar charد\n",
      "**************************************************\n",
      "ﱠ\n",
      "0 or 10\n",
      "ﹸ\n",
      "0 or 10\n",
      "ﻗ\n",
      "0 or 11\n",
      "similar charق\n",
      "**************************************************\n",
      "ﺴ\n",
      "0 or 11\n",
      "similar charس\n",
      "**************************************************\n",
      "ط\n",
      "0 or 11\n",
      "similar charط\n",
      "**************************************************\n",
      "ﺧ\n",
      "0 or 11\n",
      "similar charخ\n",
      "**************************************************\n",
      "n\n",
      "0 or 10\n",
      "ﻭ\n",
      "0 or 11\n",
      "similar charو\n",
      "**************************************************\n",
      "ﺥ\n",
      "0 or 11\n",
      "similar charخ\n",
      "**************************************************\n",
      "ﳒ\n",
      "0 or 10\n",
      "٢\n",
      "0 or 10\n",
      "آ\n",
      "0 or 11\n",
      "similar charآ\n",
      "**************************************************\n",
      "ﳝ\n",
      "0 or 10\n",
      "ﺚ\n",
      "0 or 11\n",
      "similar charث\n",
      "**************************************************\n",
      "ﻡ\n",
      "0 or 11\n",
      "similar charم\n",
      "**************************************************\n",
      "ﲪ\n",
      "0 or 10\n",
      "ﻝ\n",
      "0 or 11\n",
      "similar charل\n",
      "**************************************************\n",
      "ﻙ\n",
      "0 or 11\n",
      "similar charك\n",
      "**************************************************\n",
      "ﻜ\n",
      "0 or 11\n",
      "similar charك\n",
      "**************************************************\n",
      "8\n",
      "0 or 10\n",
      "ﻹ\n",
      "0 or 10\n",
      "ﻏ\n",
      "0 or 11\n",
      "similar charغ\n",
      "**************************************************\n",
      "ﰒ\n",
      "0 or 10\n",
      "ﺬ\n",
      "0 or 11\n",
      "similar charذ\n",
      "**************************************************\n",
      "ﻒ\n",
      "0 or 11\n",
      "similar charف\n",
      "**************************************************\n",
      "ﺁ\n",
      "0 or 11\n",
      "similar charآ\n",
      "**************************************************\n",
      "غ\n",
      "0 or 11\n",
      "similar charغ\n",
      "**************************************************\n",
      "ﺕ\n",
      "0 or 11\n",
      "similar charت\n",
      "**************************************************\n",
      "٨\n",
      "0 or 10\n",
      "1\n",
      "0 or 10\n",
      "ج\n",
      "0 or 11\n",
      "similar charج\n",
      "**************************************************\n",
      "ﺨ\n",
      "0 or 11\n",
      "similar charخ\n",
      "**************************************************\n",
      "ث\n",
      "0 or 11\n",
      "similar charث\n",
      "**************************************************\n",
      "ﺅ\n",
      "0 or 11\n",
      "similar charؤ\n",
      "**************************************************\n",
      "ﻌ\n",
      "0 or 11\n",
      "similar charع\n",
      "**************************************************\n",
      "ﺶ\n",
      "0 or 11\n",
      "similar charش\n",
      "**************************************************\n",
      "4\n",
      "0 or 10\n",
      "ﳉ\n",
      "0 or 10\n",
      "ي\n",
      "0 or 11\n",
      "similar charي\n",
      "**************************************************\n",
      "ﺋ\n",
      "0 or 11\n",
      "similar charئ\n",
      "**************************************************\n",
      "خ\n",
      "0 or 11\n",
      "similar charخ\n",
      "**************************************************\n",
      "ﻁ\n",
      "0 or 11\n",
      "similar charط\n",
      "**************************************************\n",
      "a\n",
      "0 or 10\n",
      "و\n",
      "0 or 11\n",
      "similar charو\n",
      "**************************************************\n",
      "ﺃ\n",
      "0 or 11\n",
      "similar charأ\n",
      "**************************************************\n",
      "ﲢ\n",
      "0 or 10\n",
      "ؤ\n",
      "0 or 11\n",
      "similar charؤ\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# #relate each character to the reference one\n",
    "# char_to_index_2 = dict()\n",
    "# for char in unique_chars:\n",
    "#   print(char)\n",
    "#   continue_ = input('0 or 1')\n",
    "#   if continue_ == '0':\n",
    "#     continue\n",
    "#   similar_char = input('similar char')\n",
    "#   similar_index = char_to_index[similar_char]\n",
    "#   char_to_index_2[char] = similar_index\n",
    "#   print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woo0hPNHrVon"
   },
   "outputs": [],
   "source": [
    "# #construct a dataframe with the new tokens\n",
    "# pd.DataFrame({'char': list(char_to_index_2.keys()),\n",
    "#               'value': list(char_to_index_2.values())}).to_csv('char_to_index_additional.csv', index=False)\n",
    "\n",
    "# !mv /content/char_to_index_additional.csv /content/drive/MyDrive/NLP_Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QgwUeJB1x1P",
    "outputId": "31dea680-34c7-4c62-e97c-2d6086990bb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529792/2529792 [00:08<00:00, 300594.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert the pure text into a list of sequences, each with 17 characters\n",
    "# use a step of 5 to include 12 characters from the previous and next sequence\n",
    "text_as_list = []\n",
    "for i in tqdm(range(0, len(pure_text)-17, 5)):\n",
    "  text_as_list.append([pure_text[i:i+17]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFK6MAjtZfaY",
    "outputId": "c8ce6ff7-8450-48c4-8c05-e7553419bb7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2529792/2529792 [00:06<00:00, 415584.76it/s]\n"
     ]
    }
   ],
   "source": [
    "def text_to_index(lists):\n",
    "    # construct a list that includes the character-based tokenized input words\n",
    "    # for the encoder part\n",
    "    bert_indexed_inputs = []\n",
    "    \n",
    "    # iterate over the lists\n",
    "    for text in tqdm(lists):\n",
    "      try:\n",
    "        indexes = []\n",
    "        for char in list(text[0]):\n",
    "          try:\n",
    "            indexes.append(char_to_index[char]) # try to get the index from the first dictionary\n",
    "          except:\n",
    "            indexes.append(char_to_index_2[char]) # except get the index from the second dictionary\n",
    "        bert_indexed_inputs.append(indexes)\n",
    "      except: # if the characters are not in the dictionary continue iterating\n",
    "          continue\n",
    "    return bert_indexed_inputs\n",
    "# tokenize the dataset by relating each token to its index\n",
    "indexed_text = text_to_index(text_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvHF-sNb3uOZ"
   },
   "outputs": [],
   "source": [
    "# train-validation split\n",
    "# 90% for trianing and 10% for validation\n",
    "train_len = int(0.9 * len(indexed_text))\n",
    "train_data = indexed_text[:train_len]\n",
    "valid_data = indexed_text[train_len:]\n",
    "del indexed_text, text_as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2l_2zksXEnW"
   },
   "outputs": [],
   "source": [
    "def prepare_data(indexes):\n",
    "  '''\n",
    "  Args: list of characters in the form of indexes\n",
    "  Returns: gold labels, masked labels, mask\n",
    "  '''\n",
    "  y_true = indexes # first output\n",
    "  indices_to_mask = np.random.choice(np.arange(17), size=(4,), replace=False)\n",
    "  one_hot_mask = tf.cast(tf.reduce_sum(tf.one_hot(indices_to_mask, 17), axis=0), dtype=tf.int32).numpy() # second output\n",
    "\n",
    "  index_0 = indices_to_mask[0]\n",
    "  index_1 = indices_to_mask[1]\n",
    "  index_2 = indices_to_mask[2]\n",
    "  index_3 = indices_to_mask[3]\n",
    "\n",
    "  y_masked = y_true.copy()\n",
    "\n",
    "  random_index = np.random.randint(3, len(chars)+3)\n",
    "  # ensure the masking index is not the same as the replaced one \n",
    "  while index_2 == random_index:\n",
    "    random_index = np.random.randint(3, len(chars)+3)\n",
    "\n",
    "\n",
    "  y_masked[index_0] = 2 # third output (assign mask)\n",
    "  y_masked[index_1] = 2 # third output (assing mask)\n",
    "  y_masked[index_2] = random_index # third output (assign random token)\n",
    "\n",
    "  return y_true, y_masked, one_hot_mask.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DRFfH09BUFO",
    "outputId": "ee539836-59a6-4dad-e085-cd7d740f147c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11176/11176 [00:07<00:00, 1566.36it/s]\n",
      "100%|██████████| 1242/1242 [00:00<00:00, 2674.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# construct the train and valid\n",
    "# true labels, masked labels, and masks\n",
    "\n",
    "train_true_labels = [] # true labels list\n",
    "train_masked_labels = [] # masked labels list\n",
    "train_masks = [] # masks\n",
    "# iterate over the training dataset\n",
    "for indexed_example in tqdm(train_data):\n",
    "  y_true, y_masked, one_hot_mask = prepare_data(indexed_example)\n",
    "  train_true_labels.append(y_true)\n",
    "  train_masked_labels.append(y_masked)\n",
    "  train_masks.append(one_hot_mask)\n",
    "\n",
    "valid_true_labels = [] # true labels list\n",
    "valid_masked_labels = [] # masked labels list\n",
    "valid_masks = [] # masks\n",
    "# iterate over the validation dataset\n",
    "for indexed_example in tqdm(valid_data):\n",
    "  y_true, y_masked, one_hot_mask = prepare_data(indexed_example)\n",
    "  valid_true_labels.append(y_true)\n",
    "  valid_masked_labels.append(y_masked)\n",
    "  valid_masks.append(one_hot_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9aCaZwmviVS",
    "outputId": "cd203f6e-40eb-41e1-8d65-4207a4150645"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11176/11176 [00:05<00:00, 2151.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# construct a the training dataframe initialized with zeros\n",
    "train_zeros = np.zeros((len(train_true_labels), 3))\n",
    "train_df = pd.DataFrame(columns=['x', 'y', 'mask'], data=train_zeros)\n",
    "del train_zeros\n",
    "train_df = train_df.astype('str')\n",
    "\n",
    "# populate the dataframe with the true labels, masked labels, and masks\n",
    "for i in tqdm(range(len(train_masked_labels))):\n",
    "  train_df.iloc[i, 0] = train_masked_labels[i]\n",
    "  train_df.iloc[i, 1] = train_true_labels[i]\n",
    "  train_df.iloc[i, 2] = train_masks[i]\n",
    "\n",
    "# write the dataframe to a CSV file\n",
    "train_df.to_csv('train_df.csv', index=False)\n",
    "del train_df\n",
    "# move train_df.csv to drive\n",
    "!mv /content/train_df.csv /content/drive/MyDrive/NLP_Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bl6WGRPq1Up2",
    "outputId": "b8b8cb8d-4224-42ec-a1c8-423d60273f8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [00:00<00:00, 4456.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# construct a the validation dataframe initialized with zeros\n",
    "valid_zeros = np.zeros((len(valid_true_labels), 3))\n",
    "valid_df = pd.DataFrame(columns=['x', 'y', 'mask'], data=valid_zeros)\n",
    "del valid_zeros\n",
    "valid_df = valid_df.astype('str')\n",
    "\n",
    "# populate the dataframe with the true labels, masked labels, and masks\n",
    "for i in tqdm(range(len(valid_masked_labels))):\n",
    "  valid_df.iloc[i, 0] = valid_masked_labels[i]\n",
    "  valid_df.iloc[i, 1] = valid_true_labels[i]\n",
    "  valid_df.iloc[i, 2] = valid_masks[i]\n",
    "\n",
    "# write the dataframe to a CSV file\n",
    "valid_df.to_csv('valid_df.csv', index=False)\n",
    "del valid_df\n",
    "# move valid_df.csv to drive\n",
    "!mv /content/valid_df.csv /content/drive/MyDrive/NLP_Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIqVhh8ZBul8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pre-training data preparation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
